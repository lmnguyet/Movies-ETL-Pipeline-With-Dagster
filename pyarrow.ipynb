{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "152a77e8-ae65-4b1a-baa5-53d0ecbad50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa5f222-32a6-4d72-af52-7a3d1ed2d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pa\n",
    "import pyarrow.compute as pc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b5cb56",
   "metadata": {},
   "source": [
    "## Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bda0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@asset(\n",
    "    description=\"Create table 'genres' for each genre.\",\n",
    "    io_manager_key=ABS_IO_MANAGER,\n",
    "    group_name=LAYER,\n",
    "    key_prefix=KEY_PREFIX,\n",
    "    compute_kind=\"Pandas\",\n",
    "    ins={\n",
    "        \"bronze_movies_metadata\": AssetIn(\n",
    "            key_prefix=UPSTREAM_KEY_PREFIX,\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "def silver_genres(context, bronze_movies_metadata):\n",
    "    table_name = \"silver_genres\"\n",
    "    \n",
    "    schema = pa.schema([\n",
    "        (\"genre_id\", pa.int64()),\n",
    "        (\"name\", pa.string())\n",
    "    ])\n",
    "    \n",
    "    columns = [\"genre_id\", \"name\"]\n",
    "    \n",
    "    pd_data = pa.Table.from_pandas(pd.DataFrame(columns=columns), schema=schema)\n",
    "\n",
    "    t_start = time.time()\n",
    "\n",
    "    try:\n",
    "        i = 1\n",
    "        while True:\n",
    "            batch_tstart = time.time()\n",
    "\n",
    "            df = next(bronze_movies_metadata)\n",
    "            \n",
    "            for row in df[\"genres\"]:\n",
    "                genres_list = ast.literal_eval(row)\n",
    "\n",
    "                for genre in genres_list:\n",
    "                    if pd_data.filter(pc.field(\"genre_id\") == genre[\"id\"]).num_rows > 0:\n",
    "                        continue\n",
    "\n",
    "                    record = pa.Table.from_pandas(\n",
    "                        pd.DataFrame([[genre[\"id\"], genre[\"name\"]]], columns=columns),\n",
    "                        schema=schema\n",
    "                    )\n",
    "            \n",
    "                    pd_data = pa.concat_tables([pd_data, record])\n",
    "    \n",
    "            print(f\"Completed batch {i} in: {time.time() - batch_tstart} seconds.\")\n",
    "            i += 1\n",
    "    except StopIteration:\n",
    "        pd_data = pd_data.to_pandas()\n",
    "        pd_data.sort_values(by=[\"genre_id\"], inplace=True)\n",
    "        context.log.info(f\"Check duplicated genres: {pd_data.duplicated(['genre_id']).any()}\")\n",
    "        context.log.info(f\"Completed transforming in: {time.time() - t_start} seconds.\")\n",
    "        return Output(\n",
    "            pd_data,\n",
    "            metadata={\n",
    "                \"table name\": table_name,\n",
    "                \"records count\": pd_data.shape[0],\n",
    "                \"columns count\": pd_data.shape[1],\n",
    "                \"columns\": pd_data.columns.to_list(),\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        context.log.error(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a1ff8",
   "metadata": {},
   "source": [
    "## Movies Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f561e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@asset(\n",
    "    description=\"Create table 'movies_genres' for each movie.\",\n",
    "    io_manager_key=ABS_IO_MANAGER,\n",
    "    group_name=LAYER,\n",
    "    key_prefix=KEY_PREFIX,\n",
    "    compute_kind=\"Pandas\",\n",
    "    ins={\n",
    "        \"bronze_movies_metadata\": AssetIn(\n",
    "            key_prefix=UPSTREAM_KEY_PREFIX,\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "def silver_movies_genres(context, bronze_movies_metadata):\n",
    "    table_name = \"silver_movies_genres\"\n",
    "    \n",
    "    schema = pa.schema([\n",
    "        (\"tmdb_id\", pa.int64()),\n",
    "        (\"genre_id\", pa.int64())\n",
    "    ])\n",
    "    columns = [\"tmdb_id\",\"genre_id\"]\n",
    "    \n",
    "    pd_data = pa.Table.from_pandas(pd.DataFrame(columns=columns), schema=schema)\n",
    "    \n",
    "    t_start = time.time()\n",
    "\n",
    "    try:\n",
    "        i = 1\n",
    "        while True:\n",
    "            batch_tstart = time.time()\n",
    "\n",
    "            df = next(bronze_movies_metadata)\n",
    "\n",
    "            for index, row in df.iterrows():\n",
    "                tmdb_id = row[\"id\"]\n",
    "                genres_list = ast.literal_eval(row[\"genres\"])\n",
    "\n",
    "                for genre in genres_list:\n",
    "                    record = pa.Table.from_pandas(\n",
    "                        pd.DataFrame([[tmdb_id, genre[\"id\"]]], columns=columns),\n",
    "                        schema=schema\n",
    "                    )\n",
    "                    pd_data = pa.concat_tables([pd_data, record])\n",
    "\n",
    "            context.log.info(f\"Completed batch {i} in: {time.time() - batch_tstart} seconds.\")\n",
    "            i += 1    \n",
    "    except StopIteration:\n",
    "        pd_data.sort_values(by=[\"tmdb_id\"], inplace=True)\n",
    "        context.log.info(f\"Check duplicated rows: {pd_data.duplicated().any()}\")\n",
    "        context.log.info(f\"Completed transforming in: {time.time() - t_start} seconds.\")\n",
    "        return Output(\n",
    "            pd_data,\n",
    "            metadata={\n",
    "                \"table name\": table_name,\n",
    "                \"records count\": pd_data.shape[0],\n",
    "                \"columns count\": pd_data.shape[1],\n",
    "                \"columns\": pd_data.columns.to_list(),\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        context.log.error(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e3606df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch 1 in: 7.554168701171875 seconds.\n",
      "Completed batch 2 in: 19.536564826965332 seconds.\n",
      "Completed batch 3 in: 47.36430239677429 seconds.\n",
      "Completed batch 4 in: 98.90609931945801 seconds.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '1997-08-20'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#df = next(bronze_movies_metadata)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 22\u001b[0m     tmdb_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     23\u001b[0m     genres_list \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mliteral_eval(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenres\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m genre \u001b[38;5;129;01min\u001b[39;00m genres_list:\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;66;03m#print(type(genre[\"id\"]))\u001b[39;00m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;66;03m#print(type(genre[\"name\"]))\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '1997-08-20'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import ast\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "df1 = pq.ParquetFile(\"./tmp/bronze_movies_metadata.parquet\")\n",
    "schema = pa.schema([\n",
    "        (\"tmdb_id\", pa.int64()),\n",
    "        (\"genre_id\", pa.int64())\n",
    "    ])\n",
    "columns = [\"tmdb_id\",\"genre_id\"]\n",
    "pd_data = pa.Table.from_pandas(pd.DataFrame(columns=columns), schema=schema)\n",
    "#arrow_writer = pa.RecordBatchStreamWriter(\"example.arrow\", arrow_schema)\n",
    "\n",
    "i = 1\n",
    "for bronze_movies_metadata in df1.iter_batches(batch_size=4500):\n",
    "    batch_tstart = time.time()\n",
    "    df = bronze_movies_metadata.to_pandas()\n",
    "    #df = next(bronze_movies_metadata)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        tmdb_id = int(row[\"id\"])\n",
    "        genres_list = ast.literal_eval(row[\"genres\"])\n",
    "\n",
    "        for genre in genres_list:\n",
    "            #print(type(genre[\"id\"]))\n",
    "            #print(type(genre[\"name\"]))\n",
    "            record = pa.Table.from_pandas(\n",
    "                pd.DataFrame([[tmdb_id, genre[\"id\"]]], columns=columns),\n",
    "                schema=schema\n",
    "            )\n",
    "            pd_data = pa.concat_tables([pd_data, record])\n",
    "\n",
    "    print(f\"Completed batch {i} in: {time.time() - batch_tstart} seconds.\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67449505",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6906ad",
   "metadata": {},
   "source": [
    "## Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "@asset(\n",
    "    description=\"Create table 'companies' for each production company.\",\n",
    "    io_manager_key=ABS_IO_MANAGER,\n",
    "    group_name=LAYER,\n",
    "    key_prefix=KEY_PREFIX,\n",
    "    compute_kind=\"Pandas\",\n",
    "    ins={\n",
    "        \"bronze_movies_metadata\": AssetIn(\n",
    "            key_prefix=UPSTREAM_KEY_PREFIX,\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "def silver_companies(context, bronze_movies_metadata):\n",
    "    table_name = \"silver_companies\"\n",
    "\n",
    "    columns=[\"comp_id\", \"name\"]\n",
    "    \n",
    "    pd_data = pd.DataFrame()\n",
    "\n",
    "    t_start = time.time()\n",
    "\n",
    "    try:\n",
    "        i = 1\n",
    "        while True:\n",
    "            batch_tstart = time.time()\n",
    "\n",
    "            df = next(bronze_movies_metadata)\n",
    "\n",
    "            for row in df[\"production_companies\"]:\n",
    "                comps_list = ast.literal_eval(row)\n",
    "\n",
    "                for comp in comps_list:\n",
    "                    if pd_data.isin([comp[\"id\"]]).any().any():\n",
    "                        continue\n",
    "                    pd_data.loc[len(pd_data)] = [comp[\"id\"], comp[\"name\"]]\n",
    "\n",
    "            context.log.info(f\"Completed batch {i} in: {time.time() - batch_tstart} seconds.\")\n",
    "            i += 1    \n",
    "    except StopIteration:\n",
    "        pd_data.sort_values(by=[\"comp_id\"], inplace=True)\n",
    "        context.log.info(f\"Check duplicated companies: {pd_data.duplicated(['comp_id']).any()}\")\n",
    "        context.log.info(f\"Completed transforming in: {time.time() - t_start} seconds.\")\n",
    "        return Output(\n",
    "            pd_data,\n",
    "            metadata={\n",
    "                \"table name\": table_name,\n",
    "                \"records count\": pd_data.shape[0],\n",
    "                \"columns count\": pd_data.shape[1],\n",
    "                \"columns\": pd_data.columns.to_list(),\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        context.log.error(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a653664",
   "metadata": {},
   "source": [
    "## Movies Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aa2a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "430a80e6",
   "metadata": {},
   "source": [
    "## Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c41e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a084779",
   "metadata": {},
   "source": [
    "## Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a378e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
